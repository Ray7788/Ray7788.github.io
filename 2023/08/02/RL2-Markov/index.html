<!DOCTYPE html>
<html lang="en">
    <head prefix="og: https://ogp.me/ns#">
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="color-scheme" content="light dark">
  
  <title>强化学习2:MDP Reinforcement Learning2 Markov Decision Process - Ray</title>
  
    <link rel="shortcut icon" href="/source/personal/rui.jpg">
  
  
    <link rel='manifest' href='/manifest.json'>
  

  
  
  
  <meta property="og:title" content="强化学习2:MDP Reinforcement Learning2 Markov Decision Process - Ray" />
  
  <meta property="og:type" content="article" />
  
  <meta property="og:url" content="http://example.com/2023/08/02/RL2-Markov/index.html" />
  
  <meta property="og:image" content="/source/personal/rui.jpg" />
  
  <meta property="og:article:published_time" content="2023-08-02T07:56:25.622Z" />
  
  <meta property="og:article:author" content="Rui Xu" />
  
  

  
<link rel="stylesheet" href="/css/var.css">

  
<link rel="stylesheet" href="/css/main.css">

  
<link rel="stylesheet" href="/css/typography.css">

  
<link rel="stylesheet" href="/css/code-highlighting.css">

  
<link rel="stylesheet" href="/css/components.css">

  
<link rel="stylesheet" href="/css/nav.css">

  
<link rel="stylesheet" href="/css/paginator.css">

  
<link rel="stylesheet" href="/css/footer.css">

  
<link rel="stylesheet" href="/css/post-list.css">

  
  
<link rel="stylesheet" href="/css/rainbow-banner.css">

  
  
  
<link rel="stylesheet" href="/css/toc.css">

  
  
  
  
  
<link rel="stylesheet" href="/css/post.css">

  
  
  
  
  

  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head>
    <body
        data-color-scheme="auto"
        data-uppercase-categories="true"
        
        data-rainbow-banner="true"
        data-rainbow-banner-shown="auto"
        data-rainbow-banner-month="6"
        data-rainbow-banner-colors="#e50000,#ff8d00,#ffee00,#008121,#004cff,#760188"
        
        data-config-root="/"
        
        data-toc="true"
        data-toc-max-depth="2"
        
        
    >
        <nav id="theme-nav">
    <div class="inner">
        <a class="title" href="/">Ray</a>
        <div class="nav-arrow"></div>
        <div class="nav-items">
            <a class="nav-item nav-item-home" href="/">Home</a>
            
            
            <a class="nav-item" href="/archives">Archives</a>
            
            
            
            <a class="nav-item" href="/friends">Friends</a>
            
            
            
            <a class="nav-item" href="/projects">Projects</a>
            
            
            
            <a class="nav-item" href="/about">About</a>
            
            
            
            <a class="nav-item nav-item-github nav-item-icon" href="https://github.com/Ray7788" target="_blank" aria-label="GitHub">&nbsp;</a>
            
            
            
            <a class="nav-item nav-item-search nav-item-icon" href="/search" target="_blank" aria-label="Search">&nbsp;</a>
            
            
        </div>
    </div>
</nav>
        
<article class="post">
    <div class="meta">
        

        

        <h2 class="title">强化学习2:MDP Reinforcement Learning2 Markov Decision Process</h2>
    </div>

    <div class="divider"></div>

    <div class="content">
        <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>本文基于 DeepMind research 领头人David Silver的<a target="_blank" rel="noopener" href="https://www.deepmind.com/learning-resources/introduction-to-reinforcement-learning-with-david-silver">Intro to RL</a>教学视频和互联网上各大神的笔记统一整理，如有错误请斧正，谢谢！  </p>
<p>为了一步步引入MDP，我们将循序渐进地从马尔科夫性质（Markov Process），马尔科夫奖励过程（Markov Reward Process，MRP），再到马尔科夫决策过程（Markov Decision Processes,MDP）。最后再对MDP进行部分扩展，如有限与连续MDPs(Infinite and continuous MDPs)，部分观测MDP（Partially Observable MDPs，POMDP）以及无折扣或平均奖励MDPs(Undiscounted, average reward MDPs)。</p>
<h2 id="1-马尔科夫性质（Markov-Property）"><a href="#1-马尔科夫性质（Markov-Property）" class="headerlink" title="1. 马尔科夫性质（Markov Property）"></a>1. 马尔科夫性质（Markov Property）</h2><p>进一步了解马尔科夫决策过程之前，需要先了解马尔科夫性质(Markov Property)，马尔科夫性质即未来的状态只依赖于当前状态，与过去状态无关。<br>正式的定义如下：</p>
<blockquote>
<p>马尔科夫性质（Markov Property）定义：<br>在时间步 $t + 1$ 时，环境的反馈仅取决于上一时间步$t$的状态$s$和动作$a$，与时间步$t-1$以及$t-1$步之前的时间步都没有关联性$2x -5y &#x3D; 8$。</p>
</blockquote>
<p>马尔科夫性，也就是无后效性。根据定义，当前状态捕捉了历史中所有相关的信息，所以知道了状态，状态是未来的充分统计。<br>某阶段的状态一旦确定，则此后过程的演变不再受此前各状态及决策的影响。历史(history)就可以完全丢弃。也就是说，未来与过去无关。举个不恰当的例子hhh，小米8的外观设计和前代的小米6完全没有关系。。。</p>
<p>然而在实际的环境中，智能体所需完成的任务不能够完全满足马尔科夫性质，即在时间步$t+1$的反馈不一定仅仅依赖于时间步$t$的状态和动作。但是为了简化问题的求解过程，仍然假设该任务满足马尔科夫属性（Markov Property），并通过约束环境的状态使得问题满足马尔科夫属性。</p>
<h2 id="2-马尔科夫过程（Markov-Process）"><a href="#2-马尔科夫过程（Markov-Process）" class="headerlink" title="2. 马尔科夫过程（Markov Process）"></a>2. 马尔科夫过程（Markov Process）</h2><p>AKA Markov Chain. 是一个无记忆的随机过程，可有用元组&lt;S,P&gt;表示，其中S为有限数量的状态集，P为状态转移概率矩阵。</p>
<p>状态与状态之间的转换过程即为马尔科夫过程。虽然我们可能不知道P的具体值到底是什么，但是通常我们假设P是存在的（转移概率存在，如果是确定的，无非就是概率为1），而且是稳定的（意思是从状态A到其他状态的转移虽然符合某个分布，但是其转移到某个状态的概率是确定的，不随时间变化的）。</p>
<h2 id="3-状态转移矩阵-State-Transition-Matrix"><a href="#3-状态转移矩阵-State-Transition-Matrix" class="headerlink" title="3. 状态转移矩阵(State Transition Matrix)"></a>3. 状态转移矩阵(State Transition Matrix)</h2><p>对于马尔科夫状态$s$以及后续的状态$s’$,状态转移概率可以定义为： $$ \mathbb P_{ss’}&#x3D;\mathbb P[S_{s+1}&#x3D;s’| S_t&#x3D;s] $$ 状态转移矩阵是马尔科夫过程中状态之间转移的概率所组成的矩阵，因此大小是状态数n的平方。他反映了所有当前状态$s$以及后续的状态$s’$的映射，所以他的每行概率之和必定为1。 $$ \mathbb P&#x3D; \left|\begin{matrix}P_{11} &amp; …&amp;P_{1n}\. &amp; &amp;.\P_{n1} &amp;… &amp;P_{nn}\end{matrix}\right| $$</p>
<p>$$<br>\sqrt{x^2 + y^2}<br>$$</p>

    </div>

    
    <div class="about">
        <h1>About this Post</h1>
        <div class="details">
            <p>This post is written by Rui Xu, licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc/4.0">CC BY-NC 4.0</a>.</p>
        </div>
        
        <p class="tags">
            
            <i class="icon"></i>
            <a href="/tags/AI/" class="tag">#AI</a><a href="/tags/Reinforcement-Learning/" class="tag">#Reinforcement Learning</a>
        </p>
        
    </div>
    

    <div class="container post-prev-next">
        <a class="next"></a>
        
        <a href="/2023/07/07/Using-the-Minimax-Algorithm-to-implement-the-Basic-Human-Machine-Confrontation-Game/" class="prev">
            <div>
                <div class="text">
                    <p class="label">Previous</p>
                    <h3 class="title">通过Minimax算法实现基础人机对抗博弈 (Minimax Algorithm)</>
                </div>
            </div>
        </a>
        
    </div>

    
</article>

        <footer>
    <div class="inner">
        <div class="links">
            
            <div class="group">
                <h2 class="title">Blog</h2>
                
                <a href="/" class="item">Blog</a>
                
                <a href="/archives" class="item">Archives</a>
                
                <a href="/tags" class="item">Tags</a>
                
                <a href="/categories" class="item">Categories</a>
                
                <a href="/search" class="item">Search</a>
                
                <a href="/friends" class="item">Friends</a>
                
                <a href="/projects" class="item">Projects</a>
                
                <a href="/about" class="item">About</a>
                
                <a href="/atom.xml" class="item">RSS</a>
                
            </div>
            
            <div class="group">
                <h2 class="title">Projects</h2>
                
            </div>
            
            <div class="group">
                <h2 class="title">Me</h2>
                
                <a target="_blank" rel="noopener" href="https://github.com/Ray7788" class="item">GitHub</a>
                
                <a href="ray778@foxmail.com" class="item">Email</a>
                
            </div>
            
        </div>
        <span>&copy; 2023 Rui Xu<br>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> </span>
        
        <br>
        <span class="footer-extra-description">永远相信美好的事情即将发生。Always believe something great is going to happen.</span>
        
        
            <br>
            <div class="color-scheme-toggle" role="radiogroup" id="theme-color-scheme-toggle">
                <label>
                    <input type="radio" value="light">
                    <span>Light</span>
                </label>
                <label>
                    <input type="radio" value="dark">
                    <span>Dark</span>
                </label>
                <label>
                    <input type="radio" value="auto">
                    <span>Auto</span>
                </label>
            </div>
        
    </div>
</footer>


        
<script src="/js/main.js"></script>

        
        
        

        
        <script src="https://unpkg.com/scrollreveal"></script>
        <script>
            window.addEventListener('load', () => {
                ScrollReveal({ delay: 250, reset: true, easing: 'cubic-bezier(0, 0, 0, 1)' })
                ScrollReveal().reveal('.post-list-item .cover-img img')
                ScrollReveal().reveal('.post-list-item, .card, .content p img, .content .block-large img', { distance: '60px', origin: 'bottom', duration: 800 })
            })
        </script>
        
    </body>
</html>